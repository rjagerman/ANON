#!/usr/bin/python
# -*- coding: utf-8 -*-
"""

    Alternative Internet Readme Generator
    Rolf Jagerman, Wendo Sab√©e, Laurens Versluis, Martijn de Vos
    TU Delft

This project reads the JSON files generated by the crawler and generates a table from the statistics.


Usage:

To generate and write a table to a specific and read from a specific directory, use:

    python generate_readme.py -o [the-file-to-write-to] -d [the-directory-to-read-from]

Otherwise, to use "readme.md" and "projects" as defaults, use:

    python generate_readme.py

"""

from argparse import ArgumentParser
from collections import OrderedDict
import logging
import json
import os
import codecs


def get_projects(path):
    """
    Gets a list of projects with name and description that exist in the specified directory.
    """

    project_files = filter(lambda x: x.endswith('.json'), os.listdir(path))

    projects = {}
    for project_file in project_files:
        project_file = '%s%s%s' % (path, os.sep, project_file)
        logging.debug('Loading %s' % project_file)

        project_data = open(project_file)
        current_project = json.load(project_data)
        projects[current_project['name']] = current_project

    return projects


def get_markdown_table_header(columns):
    return '%s%s%s\n' % ('| ', ' | '.join(columns.values()), ' |')


def get_markdown_table_divider(columns):
    divider = columns
    for key in divider.keys():
        divider[key] = '-' * len(divider[key])
    return get_markdown_table_header(divider)


def get_markdown_table_entry(columns, project):
    entry = []
    for key in columns.keys():
        try:
            entry.append(project[key])
        except:
            entry.append('unknown')

    return '%s%s%s\n' % ('| ', ' | '.join(entry), ' |')


def run_parser(directory='projects', output='readme.md'):
    table_columns = OrderedDict([('name', 'Name'), ('description', 'Description'), ('updated_at', 'Last activity'),
                                 ('total_contributor_count', 'Contributors'), ('total_code_lines', 'LOC')])

    projects = get_projects(directory)
    logging.info('Loaded %s projects' % len(projects))

    with codecs.open(output, 'w', 'utf-8-sig') as output_file:
        header = get_markdown_table_header(table_columns)
        output_file.write(header)

        header = get_markdown_table_divider(table_columns)
        output_file.write(header)

        for project in sorted(projects.keys()):
            logging.debug('Parsing %s' % project)
            entry = get_markdown_table_entry(table_columns, projects[project])
            output_file.write(entry, )

    logging.info('Wrote table to %s' % output)


def main():
    """
    Main entry point of the application, execution starts here
    """
    logging.getLogger().setLevel(logging.INFO)
    description = 'Parses JSON files generated by the alternative internet crawler and generates a markdown table.'
    parser = ArgumentParser(description=description)

    #parser.add_argument('-a', '--api', action='store', dest='api', metavar="api", default='', required=True,
    #                    help='Your Ohloh API key.')

    parser.add_argument('-d', '--directory', action='store', dest='directory', metavar='directory/',
                        default='projects', required=False, help='Directory to read the JSON files from')
    parser.add_argument('-o', '--output', action='store', dest='output', metavar='output.md', default='readme.md',
                        required=False, help='File to write the generated table to')

    args = parser.parse_args()

    run_parser(directory=args.directory, output=args.output)


if __name__ == "__main__":
    main()